<h3>About complexity</h3>

<p>
    Complexity is the quality of
    consisting of many interrelated parts.
    When software consists of many interrelated parts,
    it becomes more difficult to reason about.
    Software that is difficult to reason about
    is a more fertile breeding ground for bugs
    than software that is simple.
</p>

<p>
    Every problem space contains some level of inherent complexity,
    which is shared by all possible solutions.
    However, as programmers,
    we can reduce the complexity of our chosen solutions
    by limiting the interrelatedness of their constituent components.
    This is commonly referred to as favouring
    <a href="http://en.wikipedia.org/wiki/Cohesion_(computer_science)">cohesion</a>
    over <a href="http://en.wikipedia.org/wiki/Coupling_(computer_programming)">coupling</a>,
    and forms the bedrock on which axioms
    such as the <a href="http://www.objectmentor.com/resources/articles/srp.pdf">single responsibility principle</a>
    are built.
</p>

<p>
    In codebases that are large and/or unfamiliar,
    it can be difficult to know
    whether regions of complexity exist
    and where they might be.
    By defining metrics of complexity,
    the search for offending components
    can be automated
    and brought into the existing build process
    alongside other forms of static analysis
    and unit tests.
    Although the metrics themselves are far from perfect,
    they can be useful in helping to identify
    areas of code that warrant closer inspection.
    They can also be tracked over time,
    as an indicator of the direction that
    overall code quality
    may be moving in.
</p>

<p>
    The metrics that are reported by this site are generated by
    <a href="https://github.com/philbooth/escomplex">escomplex</a>,
    which can be used in such a way on JavaScript projects.
    Currently, it is able to report on
    the following complexity metrics:
    lines of code,
    number of parameters,
    cyclomatic complexity,
    cyclomatic complexity density,
    Halstead complexity measures,
    maintainability index,
    dependencies,
    first-order density,
    change cost and
    core size.
</p>

<ul class="complexity">
    <li>
        <h4 class="metric-name">Lines of code (LOC)</h4>

        <p>
            This can be either physical
            (a count of the actual lines in the file)
            or logical
            (a count of the imperative statements).
            The physical count is widely considered to be a less useful metric
            because it is easily subverted
            by collecting multiple statements on a single line of code.
            However it should be noted that the logical count can be similarly flawed,
            since the tersest expression of a solution
            is not necessarily the optimal one.
        </p>
    </li>

    <li>
        <h4 class="metric-name">Number of parameters</h4>

        <p>
            Analysed statically from the function signature,
            so no accounting is made
            for functions that rely on the <code>arguments</code> object.
            Lower is better
        </p>
    </li>

    <li>
        <h4 class="metric-name">Cyclomatic complexity</h4>

        <p>
            Defined by Thomas J. McCabe in 1976,
            this is a count
            of the number of cycles
            in the program flow control graph.
            Effectively the number of distinct paths
            through a block of code.
            Lower is better.
        </p>
    </li>

    <li>
        <h4 class="metric-name">Cyclomatic complexity density</h4>

        <p>
            Proposed as a modification
            to cyclomatic complexity
            by Geoffrey K. Gill and Chris F. Kemerer in 1991,
            this metric simply re-expresses it
            as a percentage
            of the logical lines of code.
            Lower is better.
        </p>
    </li>

    <li>
        <h4 class="metric-name">Halstead complexity measures</h4>

        <p>
            In 1977, Maurice Halstead developed a set of metrics
            which are calculated based on
            the number of distinct operators,
            the number of distinct operands,
            the total number of operators
            and the total number of operands
            in each function.
            This site picks out three Halstead measures in particular:
            difficulty, volume and effort.
        </p>

        <ul>
            <li>
                <h5 class="metric-name">Difficulty</h5>

                <div class="equation">
                    <pre><code>    (# distinct operators / 2) *
        (# operands / # distinct operands)</code></pre>
                </div>
            </li>

            <li>
                <h5 class="metric-name">Volume</h5>

                <div class="equation">
                    <pre><code>    (# operators + # operands) *
        log2(# distinct operators + # distinct operands)</code></pre>
                </div>
            </li>

            <li>
                <h5 class="metric-name">Effort</h5>

                <div class="equation">
                    <pre><code>    difficulty * volume</code></pre>
                </div>
            </li>
        </ul>
    </li>

    <li>
        <h4 class="metric-name">Maintainability index</h4>

        <p>
            Designed in 1991
            by Paul Oman and Jack Hagemeister
            at the University of Idaho,
            this metric is calculated
            at the whole program
            or module level
            from averages of the other 3 metrics,
            using the following formula:
        </p>

        <div class="equation">
            <pre><code>    171 -
        (3.42 * ln(mean effort)) -
        (0.23 * ln(mean cyclomatic complexity)) -
        (16.2 * ln(mean logical LOC))</code></pre>
        </div>

        <p>
            Values are on a logarithmic scale
            ranging from negative infinity
            up to 171,
            with greater numbers indicating a higher level of maintainability.
            In their original paper,
            Oman and Hagemeister identified 65 as the threshold value
            below which a program should be considered difficult to maintain.
        </p>
    </li>

    <li>
        <h4>Dependencies</h4>

        <p>
            A list of dependencies
            from calls to CommonJS and AMD <code>require</code>.
            Analysed statically from the function signature,
            so no accounting is made
            for dynamic calls
            where a variable or function
            is obscuring the nature of the dependency.
            Fewer is better.
        </p>
    </li>

    <li>
        <h4>First-order density</h4>

        <p>
            The percentage
            of all possible internal dependencies
            that are actually realised
            in the project.
            Lower is better.
        </p>
    </li>

    <li>
        <h4>Change cost</h4>

        <p>
            The percentage of modules affected,
            on average,
            when one module in the project
            is changed.
            Lower is better.
        </p>
    </li>

    <li>
        <h4>Core size</h4>

        <p>
            The percentage of modules
            that are both widely depended on
            and themselves depend
            on other modules.
            Lower is better.
        </p>
    </li>
</ul>

<p>
  The key point with all of these metrics
  is that the prescribed threshold values
  should not be considered as definitive indicators
  of whether a particular piece of code
  is "too complex",
  whatever that might mean.
  Software development is a broad, varied practice
  and every project is subject to
  a unique set of countless environmental factors,
  rendering such general absolutes as essentially arbitrary.
  Further, complexity itself is
  such an amorphous, multi-dimensional continuum,
  that attempting to pigeon-hole chunks of code
  at discrete points along a single axis
  is an intrinsically crude model.
</p>

<p>
  It is better to use them
  as a somewhat fuzzy, high-level mechanism,
  which can identify regions of potential interest or concern
  and from which your own programming- and domain-expertise
  can take over for a more comprehensive analysis.
</p>
